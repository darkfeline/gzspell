#!/usr/bin/env python

"""
Load data files and insert into database.

File formats:

lexicon.dat
-----------

::

    {"id": 0, "word": "apple", "frequency": 0.5, "length": 5}
    {"id": 1, "word": "banana", "frequency": 0.5, "length": 6}

graph.dat
---------

::

    [0, 1]
    [1, 0]

"""

import logging
import argparse
import json

import pymysql


def lexicon_iter(fname):
    with open(fname) as f:
        for line in f:
            x = json.loads(line)
            yield (x[k] for k in ['id', 'word', 'frequency', 'length'])


def graph_iter(fname):
    with open(fname) as f:
        for line in f:
            x = json.loads(line)
            yield x


def main(*args):
    logging.basicConfig(level=logging.DEBUG)

    parser = argparse.ArgumentParser()
    parser.add_argument('lexicon')
    parser.add_argument('graph')
    parser.add_argument('--db-server', default='localhost')
    parser.add_argument('--db-name', default='lexicon')
    parser.add_argument('--db-user', default='lexicon')
    args = parser.parse_args(args)

    with pymysql.connect(
            host=args.db_server, user=args.db_user, db=args.db_name) as cur:
        cur.executemany(' '.join(
            'INSERT INTO words (id, word, frequency, length)',
            'VALUES',
            '(%d, %s, %f, %d)'), lexicon_iter(args.lexicon))
        cur.executemany(' '.join(
            'INSERT INTO graph (word1, word2)',
            'VALUES',
            '(%d, %d)'), graph_iter(args.graph))

if __name__ == '__main__':
    import sys
    main(*sys.argv[1:])

# vim: set ft=python:
