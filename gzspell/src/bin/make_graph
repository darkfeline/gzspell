#!/usr/bin/env python3

"""
Make graph

File formats:

lexicon.dat
-----------

::

    {"id": 0, "word": "apple", "frequency": 0.5, "length": 5}
    {"id": 1, "word": "banana", "frequency": 0.5, "length": 6}

graph.dat
---------

::

    [0, 1]
    [1, 0]

"""

import logging
import argparse
import json

from gzspell import analysis

logger = logging.getLogger(__name__)


def lexicon_iter(fname):
    with open(fname) as f:
        for line in f:
            logger.debug('lexicon line: %r', line)
            x = json.loads(line)
            # 'id', 'word', 'frequency', 'length'
            yield x


def sublist(list, i):
    while True:
        try:
            yield list[i]
        except IndexError:
            break
        i += 1


def pairer(words, threshold=3):
    for i, x in enumerate(words):
        for y in sublist(words, i+1):
            logger.debug('trying to pair %r, %r', x, y)
            if analysis.editdist(x[1], y[1]) < threshold:
                logger.debug('under threshold')
                yield (x[0], y[0])


def main(*args):
    logging.basicConfig(level=logging.WARNING)

    parser = argparse.ArgumentParser()
    parser.add_argument('lexicon')
    parser.add_argument('graph')
    args = parser.parse_args(args)

    words = [(x['id'], x['word']) for x in lexicon_iter(args.lexicon)]
    with open(args.graph, 'w') as f:
        for x, y in pairer(words):
            f.write(json.dumps([x, y]) + '\n')
            f.write(json.dumps([y, x]) + '\n')


if __name__ == '__main__':
    import sys
    main(*sys.argv[1:])

# vim: set ft=python:
